# -*- coding: utf-8 -*-
"""Graph Theory.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/149dpuhJIc07ZuLcc4D2CTGRPh825SyaD
"""

import networkx as nx
import matplotlib.pyplot as plt

# Create the graph
G = nx.Graph()
nodes = ['a', 'b', 'c', 'd', 'e', 'f', 'g']
G.add_nodes_from(nodes)
edges = [
    ('a', 'b'),
    ('b', 'd'),
    ('d', 'e'),
    ('d', 'g'),
    ('d', 'c'),
    ('e', 'f'),
]
G.add_edges_from(edges)

# Plot the graph
pos = nx.spring_layout(G)  # Positions of the nodes
nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', width=1, font_size=10)

# Draw edge weights if available
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)

plt.title("Graph")
plt.show()

import networkx as nx
import matplotlib.pyplot as plt

# Create an empty graph
graph = nx.Graph()

# Add four nodes
graph.add_nodes_from(['a', 'b', 'c', 'd', 'e', 'f'])

# Add edges between all nodes
graph.add_edges_from(
    [('a', 'd'), ('a', 'c'),
     ('d', 'c'), ('d', 'e'),
     ('e', 'c'), ('e', 'b'),
     ('e', 'f'), ('b', 'c')
    ])

# Calculate edge betweenness
edge_betweenness = nx.edge_betweenness_centrality(graph)

# Print the edge betweenness for each edge
for edge, betweenness in edge_betweenness.items():
    print(f"Edge {edge}: {betweenness}")

# Check for bridges
bridges = list(nx.bridges(graph))

# Print the bridges
print("Bridges in the graph:", bridges)

# Draw the graph
pos = nx.spring_layout(graph)
nx.draw_networkx(graph, pos, with_labels=True, node_color='lightblue', node_size=1000, font_size=12, font_color='black')

plt.show()

"""# Epidemics on networks

![SI.png](attachment:SI.png)

The SI model is one of the simplest epidemic spreading models that can be applied to a network. In simple, each node of the network can be in each of the following states:

**S:** A susceptible individual (node). When a susceptible and an infectious individual come into "infectious contact", the susceptible individual contracts the disease and transitions to the infectious compartment.<br>

**I:** An infected individual (node). These are individuals who have been infected and are capable of infecting susceptible individuals.<br>

There is an alternative to the SI model, the SIR model, which incorporates a third state:

**R:** for the number of removed (and immune) or deceased individuals. These are individuals who have been infected and have either recovered from the disease and entered the removed compartment, or died. It is assumed that the number of deaths is negligible with respect to the total population. This compartment may also be called "recovered" or "resistant".

![image.png](attachment:image.png)

## EoN Library

First we install the EoN library
"""

pip install EoN

import EoN, networkx as nx, numpy as np

"""## A simple example"""

H=nx.MultiDiGraph()

H.add_nodes_from(["A","B","C","D","E"])
H.add_edges_from([("A","D"),("B","D"),("C","B"),("C","D"),("A","E"),("D","E"),("B","E")])
nx.draw(H,with_labels=True, font_color='w')

"""Small parenthesis: add attributes to nodes"""

com={"A":1,"B":2,"C":1,"D":1,"E":2}

nx.set_node_attributes(H, com, "community")

H.nodes()["A"]

"""--------------------------
Let's run a simple SIR simulation
"""

EoN.fast_SIR(H, tau=1, gamma=0, rho=0.5, tmax = 100)

"""We want to store each output array"""

t, S, I, R = EoN.fast_SIR(H, tau=1, gamma=0, rho=0.5, tmax = 10)

plt.plot(t, I, color = 'r', alpha=0.7,label="Infected")
plt.plot(t, S, color = 'g', alpha=0.7,label="Susceptible")
plt.plot(t, R, color = 'b', alpha=0.7,label="Recovered")
plt.legend()

"""How to get states for particular nodes in time?"""

tmax = 300
tau = 0.1    #transmission rate
gamma = 0    #recovery rate


#run simulation with Simulation_Investigation option:

sim = EoN.fast_SIR(H, tau, gamma, return_full_data=True,initial_infecteds="A", tmax = tmax)

"""Now the "sim" object has all the information we need.
For example, if we want to know the history of a node through time:
"""

sim.node_history("E")

sim.node_status("E",1)

"""Let's print the state of each node for t=1 (Menti)


"""



"""Now, let's retrieve the moment when each node gets infected"""



"""### Solution:"""

for node in H:
    if(len(sim.node_history(node)[0])>=2):
        print(node + " " + str(sim.node_history(node)[0][1]))
    else:
        print(node + " " + "NA")

"""## Taking averages over several simulations

First we create what is called a "dictionary", containing a "key" for every node
"""

times = {}
for node in H:
    times[node]=[]

times

"""Now we run 10 simulations, and we store the values of times in the "times" dictionary"""

# Run 10 simulations
for simulation in np.arange(10):

    #Run an SIR model and return the whole data, and store it in sim
    sim = EoN.fast_SIR(H, tau, gamma, return_full_data=True,initial_infecteds="A", tmax = tmax)

    #we loop through the nodes
    for node in H:

        #if they changed state
        if(len(sim.node_history(node)[0])>=2):

            #we append the time when this happened
            times[node].append(sim.node_history(node)[0][1])

"""Finally, we calculate mean values for each node"""

for node in times:
    if (len(node)>0):
        times[node]=sum(times[node])/len(node)

times

sim.display(time=0,pos={"A":[0,1],"B":[1,1],"C":[1,0],"D":[1,2],"E":[2,2]})
sim.display(time=10,pos={"A":[0,1],"B":[1,1],"C":[1,0],"D":[1,2],"E":[2,2]})

"""-----------
## SIR over a real network

Let's use the network provided in topic 2
"""

fh = open("Edges.txt", "rb")
G = nx.read_edgelist(fh)
fh.close()

n=len(G.nodes())

m=len(G.edges())

m

G.edges()

"""Why is "m" less than the number of rows?"""

fh = open("Edges.txt", "rb")
G = nx.read_edgelist(fh, create_using=nx.MultiDiGraph)
fh.close()

m=len(G.edges())
n=len(G.nodes())

m

"""Now let's run a basic SIR model"""

tmax = 10
tau = 0.5           #transmission rate
gamma = 1    #recovery rate
rho = 0.005      #random fraction initially infected

 #run simulation
t, S, I, R = EoN.fast_SIR(G, tau, gamma, rho=rho, tmax = tmax)
plt.plot(t, I, color = 'r', alpha=0.7,label="Infected")
plt.plot(t, S, color = 'g', alpha=0.7,label="Susceptible")
plt.plot(t, R, color = 'b', alpha=0.7,label="Recovered")
plt.legend()

"""What about other models?"""

tmax = 10
tau = 0.5           #transmission rate
gamma = 0.6    #recovery rate
rho = 0.4      #random fraction initially infected

 #run simulation
t, S, I = EoN.fast_SIS(G, tau, gamma, rho=rho, tmax = tmax)
plt.plot(t, I, color = 'r', alpha=0.7,label="Infected")
plt.plot(t, S, color = 'g', alpha=0.7,label="Susceptible")
plt.legend()

"""<br></br>
Let's compare it with a random network
"""

G2=nx.gnm_random_graph(n, m)

tau=0.5
gamma=0.8
rho=0.05
t, S, I, R = EoN.fast_SIR(G, tau, gamma, rho=rho, tmax = tmax)
t2, S2, I2, R2 = EoN.fast_SIR(G2, tau, gamma, rho=rho, tmax = tmax)
plt.plot(t2, I2, color = 'r', alpha=0.7,label="Irnd")
plt.plot(t2, S2, color = 'g', alpha=0.7,label="Srnd")
plt.plot(t2, R2, color = 'b', alpha=0.7,label="Rrnd")
plt.plot(t, I, color = 'r', linestyle='dashed', alpha=0.7,label="I")
plt.plot(t, S, color = 'g', linestyle='dashed',alpha=0.7,label="S")
plt.plot(t, R, color = 'b', linestyle='dashed', alpha=0.7,label="R")
plt.legend()



"""# NetworkX
## Creating a basic graph
Let's start creating a very basic network:

![Captura%20de%20Pantalla%202021-03-02%20a%20la%28s%29%2010.14.11.png](attachment:Captura%20de%20Pantalla%202021-03-02%20a%20la%28s%29%2010.14.11.png)
"""

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import csv

G = nx.Graph()

G.add_nodes_from([1,2,3,4])

G.edges()

G.clear()

G.nodes()

G.add_nodes_from(["A","B","C","D"])

G.add_edge("A","B")

G.edges()

G.add_edges_from([("A","D"),("B","D"),("C","B"),("C","D")])

nx.draw(G)

nx.draw(G,with_labels=True, font_color='r')

"""## Reading datasets

#### 1. Reading a text file

Now let's load Topic 1 network
"""

fh = open("Edges.txt", "rb")
G = nx.read_edgelist(fh)
fh.close()

import pandas as pd

mod = pd.read_csv("mod.csv")

firstCol = mod['modularity_class'].tolist()

"""---
<br>

#### 2. Reading .gml files
"""

H = nx.read_gml("karate.gml",label=None)

nx.draw(H)

nx.draw(H,with_labels=True)

"""Let's color nodes according to how important they are"""

clustering = nx.clustering(H)

clustering

values = np.fromiter(clustering.values(), dtype=float)

values

nx.draw(H, node_color=values, node_size=800, cmap=plt.cm.Blues)

"""## Some final remarks: dictionaries, lists, arrays, dataframes..."""

type(clustering)

a = [1,2,3,4]

type(a)

b = np.arange(200)

type(b)

clustering.values()

a.values()

"""Transforming a dictionary to a List"""

clusteringList = list(clustering.values())

clusteringList



import networkx as nx
import matplotlib.pyplot as plt
import numpy as np

G = nx.DiGraph()

initial_graph = [(1,2),(2,3),(3,1)]
G.add_edges_from(initial_graph)

for node in range(10):
  degree_dict = dict(G.degree())
  node_list = list(degree_dict.keys())
  probability_list = list(degree_dict.values())

  probability_list_normalised = []
  sum_p = sum(probability_list)
  for i in range(len(probability_list)):
      probability_list_normalised.append(probability_list[i] / sum_p)

  chosen_node_list = []
  for _ in range(3):
    chosen_node = np.random.choice(node_list, p=probability_list_normalised)
    while chosen_node in chosen_node_list:
      chosen_node = np.random.choice(node_list, p=probability_list_normalised)

    chosen_node_list.append(chosen_node)

  for cn in chosen_node_list:
    G.add_edge(cn,node+3)

nx.draw_networkx(G)

page_rank_dict = nx.pagerank(G)
page_rank_dict

plt.plot(list(page_rank_dict.keys()),list(page_rank_dict.values()))
plt.xlabel("Node")
plt.ylabel("PageRank")

out_degree_dict = dict(G.out_degree())
out_degree_dict

fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 10))
ax1.plot(list(page_rank_dict.keys()),list(page_rank_dict.values()))
ax1.set_xlabel("Node")
ax1.set_ylabel("PageRank")

ax2.plot(list(out_degree_dict.keys()),list(out_degree_dict.values()))
ax2.set_xlabel("Node")
ax2.set_ylabel("OutDegree")

betweeness_dict = nx.betweenness_centrality(G)
betweeness_dict

fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 10))
ax1.plot(list(page_rank_dict.keys()),list(page_rank_dict.values()))
ax1.set_xlabel("Node")
ax1.set_ylabel("PageRank")

ax2.plot(list(betweeness_dict.keys()),list(betweeness_dict.values()))
ax2.set_xlabel("Node")
ax2.set_ylabel("Betweeness")

G = nx.DiGraph()
initial_graph = [(1,2),(2,3),(3,1)]
G.add_edges_from(initial_graph)

for node in range(1000):
  degree_dict = dict(G.degree())
  node_list = list(degree_dict.keys())
  probability_list = list(degree_dict.values())

  probability_list_normalised = []
  sum_p = sum(probability_list)
  for i in range(len(probability_list)):
      probability_list_normalised.append(probability_list[i] / sum_p)

  chosen_node_list = []
  for _ in range(3):
    chosen_node = np.random.choice(node_list, p=probability_list_normalised)
    while chosen_node in chosen_node_list:
      chosen_node = np.random.choice(node_list, p=probability_list_normalised)

    chosen_node_list.append(chosen_node)


  for cn in chosen_node_list:
    G.add_edge(cn,node+3)


fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize=(15, 10))
page_rank_dict = nx.pagerank(G)
ax1.plot(list(page_rank_dict.keys()),list(page_rank_dict.values()))
ax1.set_xlabel("Node")
ax1.set_ylabel("PageRank")

out_degree_dict = dict(G.out_degree())
ax2.plot(list(out_degree_dict.keys()),list(out_degree_dict.values()))
ax2.set_xlabel("Node")
ax2.set_ylabel("OutDegree")

betweeness_dict = nx.betweenness_centrality(G)
ax3.plot(list(betweeness_dict.keys()),list(betweeness_dict.values()))
ax3.set_xlabel("Node")
ax3.set_ylabel("Betweeness")

fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize=(15, 10))
page_rank_values = list(page_rank_dict.values())
page_rank_values.sort(reverse=True)
ax1.plot(list(page_rank_dict.keys()),page_rank_values)
ax1.set_xlabel("Node")
ax1.set_ylabel("PageRank")

out_degree_values = list(out_degree_dict.values())
out_degree_values.sort(reverse=True)
ax2.plot(list(out_degree_dict.keys()),out_degree_values)
ax2.set_xlabel("Node")
ax2.set_ylabel("OutDegree")

betweeness_list = list(betweeness_dict.values())
betweeness_list.sort(reverse=True)
ax3.plot(list(betweeness_dict.keys()),betweeness_list)
ax3.set_xlabel("Node")
ax3.set_ylabel("Betweeness")

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np

G = nx.Graph()

initial_graph = [(1,2),(2,3),(3,1)]
G.add_edges_from(initial_graph)

nx.draw_networkx(G)

degree_dict = dict(G.degree())

degree_dict

node_list = list(degree_dict.keys())
degree_list = list(degree_dict.values())

print(node_list, degree_list)

plt.bar(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

probability_list = degree_list

np.random.choice(node_list, p=probability_list)

probability_list_normalised = []
sum_p = sum(probability_list)
for i in range(len(probability_list)):
    probability_list_normalised.append(probability_list[i] / sum_p)

probability_list_normalised

chosen_node = np.random.choice(node_list, p=probability_list_normalised)

chosen_node

G.add_edge(4,chosen_node)
nx.draw_networkx(G)

degree_dict = dict(G.degree())
node_list = list(degree_dict.keys())
degree_list = list(degree_dict.values())

plt.bar(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

degree_dict = dict(G.degree())
print('degree_dict', degree_dict)

node_list = list(degree_dict.keys())
probability_list = list(degree_dict.values())

probability_list_normalised = []
sum_p = sum(probability_list)
for i in range(len(probability_list)):
    probability_list_normalised.append(probability_list[i] / sum_p)
print('probability_list_normalised', probability_list_normalised)

chosen_node = np.random.choice(node_list, p=probability_list_normalised)
print('chosen_node', chosen_node)

G.add_edge(5,chosen_node)
nx.draw_networkx(G)

degree_dict = dict(G.degree())
node_list = list(degree_dict.keys())
degree_list = list(degree_dict.values())

plt.bar(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

for node in range(10):
  degree_dict = dict(G.degree())
  node_list = list(degree_dict.keys())
  probability_list = list(degree_dict.values())

  probability_list_normalised = []
  sum_p = sum(probability_list)
  for i in range(len(probability_list)):
      probability_list_normalised.append(probability_list[i] / sum_p)

  chosen_node = np.random.choice(node_list, p=probability_list_normalised)
  print('chosen_node', chosen_node)

  G.add_edge(node+5,chosen_node)

nx.draw_networkx(G)

degree_dict = dict(G.degree())
node_list = list(degree_dict.keys())
degree_list = list(degree_dict.values())

plt.bar(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

G = nx.Graph()
initial_graph = [(1,2),(2,3),(3,1)]
G.add_edges_from(initial_graph)

for node in range(1000):
  degree_dict = dict(G.degree())
  node_list = list(degree_dict.keys())
  probability_list = list(degree_dict.values())

  probability_list_normalised = []
  sum_p = sum(probability_list)
  for i in range(len(probability_list)):
      probability_list_normalised.append(probability_list[i] / sum_p)

  chosen_node = np.random.choice(node_list, p=probability_list_normalised)

  G.add_edge(node+3,chosen_node)

nx.draw_networkx(G)

degree_dict = dict(G.degree())
node_list = list(degree_dict.keys())
degree_list = list(degree_dict.values())

plt.bar(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

degree_list.sort(reverse=True)

plt.plot(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

plt.loglog(node_list,degree_list)
plt.xlabel("Node")
plt.ylabel("Degree")

for r in range(10):
  G = nx.Graph()
  initial_graph = [(1,2),(2,3),(3,1)]
  G.add_edges_from(initial_graph)

  for node in range(1000):
    degree_dict = dict(G.degree())
    node_list = list(degree_dict.keys())
    probability_list = list(degree_dict.values())

    probability_list_normalised = []
    sum_p = sum(probability_list)
    for i in range(len(probability_list)):
        probability_list_normalised.append(probability_list[i] / sum_p)

    chosen_node = np.random.choice(node_list, p=probability_list_normalised)

    G.add_edge(node+3,chosen_node)


  degree_dict = dict(G.degree())
  node_list = list(degree_dict.keys())
  degree_list = list(degree_dict.values())

  degree_list.sort(reverse=True)
  plt.loglog(node_list,degree_list)

plt.xlabel("Node")
plt.ylabel("Degree")